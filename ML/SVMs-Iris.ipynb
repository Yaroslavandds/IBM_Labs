{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries and load the dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                             # Read system parameters.\n",
    "import numpy as np                     # Work with multi-dimensional arrays and matrices.\n",
    "import pandas as pd                    # Manipulate and analyze data.\n",
    "import matplotlib as mpl               # Create 2D charts.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb                   # Perform data visualization.\n",
    "import sklearn                         # Perform data mining and analysis.\n",
    "from sklearn import datasets\n",
    "\n",
    "# Summarize software libraries used.\n",
    "print('Libraries used in this project:')\n",
    "print('- Python {}'.format(sys.version))\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- pandas {}'.format(pd.__version__))\n",
    "print('- Matplotlib {}'.format(mpl.__version__))\n",
    "print('- scikit-learn {}\\n'.format(sklearn.__version__))\n",
    "\n",
    "# Load the dataset.\n",
    "iris = datasets.load_iris()\n",
    "print('Loaded {} records.'.format(len(iris.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquainted with the dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert array to pandas DataFrame.\n",
    "data_raw = pd.DataFrame(iris['data'], columns = iris['feature_names'])\n",
    "data_raw['target'] = iris['target']\n",
    "\n",
    "print(data_raw.info())      # View data types and see if there are missing entries.\n",
    "data_raw.head(10)           # View first 10 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine a general summary of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:.2f}'.format): \n",
    "    print(data_raw.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 2))\n",
    "bplot = sb.boxplot(x = 'sepal width (cm)', data = data_raw, orient = 'h', fliersize = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the dimensionality of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data'][:, :2]  # Only use first two features (sepal length and sepal width).\n",
    "y = iris['target']\n",
    "\n",
    "print(\"\\nBefore reduction:\")\n",
    "print(\"X dataset dimensions are\", X.shape)\n",
    "print(\"y dataset dimensions are\", y.shape)\n",
    "\n",
    "# Only use labels 0 and 1 (setosa and versicolor).\n",
    "class_labels = (y == 0) | (y == 1)\n",
    "X = X[class_labels]\n",
    "y = y[class_labels]\n",
    "\n",
    "print(\"\\nAfter reduction:\")\n",
    "print(\"X dataset dimensions are\", X.shape)\n",
    "print(\"y dataset dimensions are\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the separation between classes using a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sepal length along x-axis, sepal width along y-axis.\n",
    "scatter_x = X[:, 0]\n",
    "scatter_y = X[:, 1]\n",
    "\n",
    "cdict = {0: 'green', 1: 'grey'}\n",
    "\n",
    "# Generate scatter plot with legend.\n",
    "for c_label in np.unique(y):\n",
    "    if c_label == 0:\n",
    "        iris = 'setosa'\n",
    "    if c_label == 1:\n",
    "        iris = 'versicolor'\n",
    "    \n",
    "    ix = np.where(y == c_label)\n",
    "    plt.scatter(scatter_x[ix], scatter_y[ix], c = cdict[c_label], label = iris, s = 40)\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"Sepal length\", fontsize = 13)\n",
    "plt.ylabel(\"Sepal width\", fontsize = 13)\n",
    "plt.annotate('Possible outlier', xy = (4.4, 2.3), xytext = (2.9, 2.2),\n",
    "             arrowprops = dict(color= 'black'), fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a decision boundary for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model, is_svm):\n",
    "    scatter_x = X[:, 0]\n",
    "    scatter_y = X[:, 1]\n",
    "\n",
    "    cdict = {0: 'green', 1: 'grey'}\n",
    "\n",
    "    for c_label in np.unique(y):\n",
    "        if c_label == 0:\n",
    "            iris = 'setosa'\n",
    "        if c_label == 1:\n",
    "            iris = 'versicolor'\n",
    "\n",
    "        ix = np.where(y == c_label)\n",
    "        plt.scatter(scatter_x[ix], scatter_y[ix], c = cdict[c_label], label = iris, s = 40)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Sepal length\", fontsize = 13)\n",
    "    plt.ylabel(\"Sepal width\", fontsize = 13)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # Create grid.\n",
    "    xx = np.linspace(xlim[0], xlim[1], 40)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 40)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = model.decision_function(xy).reshape(XX.shape)  # Use model decision function to plot boundary.\n",
    "    \n",
    "    if is_svm == True:\n",
    "        # Plot decision boundary and margins.\n",
    "        ax.contour(XX, YY, Z, colors = 'r', levels = [-1, 0, 1], \n",
    "                   linestyles=['--', '-', '--'])\n",
    "        \n",
    "        # Plot support vectors.\n",
    "        ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                   s = 100, linewidth = 1, facecolors = 'none', edgecolors = 'k')\n",
    "    else:\n",
    "        ax.contour(XX, YY, Z, colors = 'r', levels = [0], \n",
    "                   linestyles=['-'])\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "print('Function to plot the decision boundary has been defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a basic logistic regression model and plot its decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(solver = 'liblinear', random_state = 1936)\n",
    "log_reg.fit(X, y);\n",
    "\n",
    "plot_decision_boundary(X, y, log_reg, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an SVM model and plot its decision boundary plus margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'linear', C = 100, random_state = 1936)\n",
    "svm.fit(X, y)\n",
    "\n",
    "plot_decision_boundary(X, y, svm, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the regularization penalty to soften the margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear', C = 0.1, random_state = 1936)\n",
    "svm.fit(X, y)\n",
    "\n",
    "plot_decision_boundary(X, y, svm, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_columns = ['target']\n",
    "\n",
    "training_columns = ['sepal length (cm)', 'sepal width (cm)' , 'petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "# Split the training and test datasets and their labels.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_raw[training_columns],\n",
    "                                                                            data_raw[label_columns],\n",
    "                                                                            random_state = 1936)\n",
    "\n",
    "print('The training and test datasets and their labels have been split.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate an SVM model using a holdout test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'linear', C = 100, random_state = 1936)\n",
    "svm.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Score using the test data.\n",
    "score = svm.score(X_test, y_test)\n",
    "\n",
    "print('Accuracy: {:.0f}%'.format(score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the SVM model with grid search and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm = SVC(gamma = 'auto', random_state = 1936)\n",
    "\n",
    "grid = [{'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "         'C': [0.01, 0.1, 1, 5, 10, 25, 50, 100]}]\n",
    "\n",
    "search = GridSearchCV(svm, param_grid = grid, scoring = 'accuracy', cv = 5, iid = False)\n",
    "search.fit(X_train, np.ravel(y_train));\n",
    "\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score using the test data.\n",
    "score = search.score(X_test, y_test)\n",
    "\n",
    "print('Accuracy: {:.0f}%'.format(score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the optimized SVM model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set to evaluate.\n",
    "results_comparison = X_test.copy()\n",
    "results_comparison['Predicted Iris'] = search.predict(X_test)\n",
    "results_comparison['Actual Iris'] = y_test.copy()\n",
    "\n",
    "# Map labels to actual Iris names.\n",
    "iris_encode = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "    \n",
    "results_comparison['Predicted Iris'] = results_comparison['Predicted Iris'].map(iris_encode)\n",
    "results_comparison['Actual Iris'] = results_comparison['Actual Iris'].map(iris_encode)\n",
    "\n",
    "# View examples of the predictions compared to actual Iris.\n",
    "results_comparison.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
