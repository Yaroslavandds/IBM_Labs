{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                             # Read system parameters\n",
    "import os                              # Interact with the operating system\n",
    "import numpy as np                     # Work with multi-dimensional arrays and matrices\n",
    "import pandas as pd                    # Manipulate and analyze data\n",
    "import matplotlib                      # Create 2D charts\n",
    "import scipy as sp                     # Perform scientific computing and advanced mathematics\n",
    "import sklearn                         # Perform data mining and analysis\n",
    "import seaborn as sb                   # Perform data visualization\n",
    "\n",
    "# Summarize software libraries used\n",
    "print('Libraries used in this project:')\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- Pandas {}'.format(pd.__version__))\n",
    "print('- Matplotlib {}'.format(matplotlib.__version__))\n",
    "print('- SciPy {}'.format(sp.__version__))\n",
    "print('- Scikit-learn {}'.format(sklearn.__version__))\n",
    "print('- Python {}\\n'.format(sys.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIR = '.'\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, 'housing_data')\n",
    "print('Data files in this project:', os.listdir(DATA_PATH) )\n",
    "\n",
    "# Read the raw dataset\n",
    "data_raw_file = os.path.join( DATA_PATH, 'kc_house_data.csv' )\n",
    "data_raw = pd.read_csv( data_raw_file )\n",
    "print('Loaded {} records from {}.\\n'.format(len(data_raw), data_raw_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquainted with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_raw.info())     # View features and data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show example records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first ten records\n",
    "print(data_raw.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('float_format', '{:.2f}'.format): \n",
    "    print( data_raw.describe() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the most common values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize most common values for features with non-continuous or categorical values\n",
    "features_to_summarize = ['view','waterfront','grade','zipcode','bedrooms','bathrooms','floors']\n",
    "data_raw[features_to_summarize].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show correlations with price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for correlations with price\n",
    "print('Pearson correlations with price')\n",
    "corr_matrix = data_raw.corr()\n",
    "corr_matrix['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze cross correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib for visualization\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify size and title for the visualization\n",
    "f, axes = plt.subplots(figsize=(20, 20))\n",
    "plt.title('All Correlations',fontsize=32)\n",
    "\n",
    "# For the purpose of visualization, we'll use a different order for the features.\n",
    "# We'll start with price, to make it easier to compare all other features with it.\n",
    "features = ['price','bedrooms','bathrooms',\n",
    "            'sqft_living','sqft_living15','sqft_lot','sqft_lot15','sqft_above','sqft_basement',\n",
    "            'floors','waterfront',\n",
    "            'view','condition','grade',\n",
    "            'yr_built','yr_renovated',\n",
    "            'zipcode','lat','long']\n",
    "\n",
    "# Use Seaborn library to plot the correlation matrix as a heatmap\n",
    "sb.heatmap(data_raw[features].corr(),\n",
    "           linewidths = 3.0,\n",
    "           square = True,\n",
    "           cmap = 'Greens',\n",
    "           linecolor='w',\n",
    "           annot=True,\n",
    "           annot_kws={'size':11},\n",
    "           cbar_kws={'shrink': .5});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use histograms to visualize the distribution of various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "data_raw.hist(figsize=(20,15));\n",
    "plt.figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize with a geographic map to gain insights regarding location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# To avoid overwhelming the visualization tool, we'll only plot every Nth house.\n",
    "n_homes = 20\n",
    "data_raw_subset = data_raw.sort_values(by =['price'], ascending = False)[::n_homes]\n",
    "\n",
    "# Output highest house price\n",
    "max_price = data_raw_subset.loc[data_raw_subset['price'].idxmax()]['price']\n",
    "print(f'The highest home price in this dataset is ${max_price:,.0f}')\n",
    "\n",
    "# Descriptions of the building grades used in King County\n",
    "# Values obtained from http://www5.kingcounty.gov/sdc/FGDCDocs/resbldg_extr_faq.htm\n",
    "bldg_grades = ['Unknown','Cabin','Substandard','Poor','Low','Fair',\n",
    "               'Low Average','Average','Good','Better',\n",
    "               'Very Good','Excellent','Luxury','Mansion','Exceptional Properties']\n",
    "\n",
    "# Use Folium library to plot values on a map.\n",
    "import folium\n",
    "\n",
    "# Generate the base map, centering on King County.\n",
    "base_map = folium.Map(location = [47.5300, -122.2000],\n",
    "                      control_scale = True, \n",
    "                      max_zoom = 20,\n",
    "                      zoom_start = 10,\n",
    "                      zoom_control = True)\n",
    "\n",
    "# Plot homes by price.\n",
    "for index, row in data_raw_subset.iterrows():\n",
    "    \n",
    "    # Get the grade description for this row.\n",
    "    grade_desc = bldg_grades[row['grade']]\n",
    "    waterfront_desc = \"Yes\" if (row['waterfront'] == 1) else \"No\"\n",
    "\n",
    "    # Add popup text. Click each point to show details.\n",
    "    popup_text = '<br>'.join(['King&nbsp;County&nbsp;Housing&nbsp;Sales&nbsp;Data',\n",
    "                              'Price:&nbsp;${:,.0f}',\n",
    "                              'Sqft&nbsp;Living:&nbsp;{:,.0f}',\n",
    "                              'Grade:&nbsp;{}&nbsp;({})',\n",
    "                              'Location:&nbsp;[{:.3f},{:.3f}]',\n",
    "                              'Waterfront:&nbsp;{}',\n",
    "                              'Zipcode:&nbsp;{}'])\n",
    "    \n",
    "    popup_text = popup_text.format(row['price'],\n",
    "                                   row['sqft_living'],\n",
    "                                   row['grade'], grade_desc,\n",
    "                                   row['lat'], row['long'],\n",
    "                                   waterfront_desc,\n",
    "                                   row['zipcode'])\n",
    "    \n",
    "    # Add each home to the map, but show larger dots for higher prices.\n",
    "    scaling_value = (row['price'] / max_price)      # 1.0 for highest price.\n",
    "    folium.CircleMarker([row['lat'], row['long']],\n",
    "                        radius = 25 * scaling_value,\n",
    "                        weight = 1,\n",
    "                        fill = True,\n",
    "                        fillColor = '#0000FF',\n",
    "                        fillOpacity = 0.7,\n",
    "                        color = '#0000FF',\n",
    "                        opacity = 0.7,\n",
    "                        popup = popup_text).add_to(base_map)\n",
    "\n",
    "base_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Price is the dependent variable (value to be predicted), so it will be\n",
    "# removed from the training data and put into a separate dataframe for labels.\n",
    "\n",
    "label_columns = ['price']\n",
    "\n",
    "training_columns = ['sqft_living',\n",
    "                   'grade',  \n",
    "                   'bathrooms', \n",
    "                   'view',\n",
    "                   'sqft_basement', \n",
    "                   'bedrooms', \n",
    "                   'lat',\n",
    "                   'waterfront',\n",
    "                   'floors',\n",
    "                   'yr_renovated',\n",
    "                   'sqft_lot',\n",
    "                   'yr_built',\n",
    "                   'condition',\n",
    "                   'long', \n",
    "                   'zipcode']\n",
    "\n",
    "# Split independent and dependent variables.\n",
    "data_train,data_test,data_train_labels,data_test_labels = train_test_split(data_raw[training_columns], \n",
    "                                                                           data_raw[label_columns], \n",
    "                                                                           random_state = 42)\n",
    "\n",
    "# Compare the number of rows and columns in the original data to the training and testing sets\n",
    "print(f'Original Set:      {data_raw.shape}')\n",
    "print('------------------------------')\n",
    "print(f'Training Features: {data_train.shape}')\n",
    "print(f'Testing Features:  {data_test.shape}')\n",
    "print(f'Training Labels:   {data_train_labels.shape}')\n",
    "print(f'Testing Labels:    {data_test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and test a linear regression model - Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from time import time\n",
    "\n",
    "# Create a linear regression model\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Fit the model using training data and labels\n",
    "start = time()\n",
    "regressor.fit(data_train, data_train_labels);\n",
    "end=time()\n",
    "train_time = (end - start) * 1000\n",
    "print('Model took {:,.2f} milliseconds to fit.'.format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the holdout dataset to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance using test data and labels\n",
    "score = regressor.score(data_test, data_test_labels)\n",
    "'Score: {}%'.format(int(round(score * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare predicted values to actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted_prices = regressor.predict(data_test)\n",
    "predictions = data_test_labels.copy()\n",
    "predictions['predicted'] = predicted_prices\n",
    "\n",
    "# View examples comparing actual prices to predicted prices\n",
    "with pd.option_context('float_format', '${:,.2f}'.format): print( predictions.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pred_to_actual(chart_description):\n",
    "\n",
    "    N = 10 # Plot every Nth value to save time and space\n",
    "    pred_df = predictions.sort_values('price')[::N]\n",
    "\n",
    "    pred_df['diff'] = pred_df['price'] - pred_df['predicted']\n",
    "    pred_df['recnum'] = np.arange(len(pred_df))\n",
    "    pred_df['error_pct'] = abs(pred_df['diff']/pred_df['price'])*100\n",
    "\n",
    "    ax = plt.figure(figsize=[18,10])\n",
    "    plt.ylabel('Price')\n",
    "    plt.xlabel('House')\n",
    "    plt.plot(pred_df['recnum'], pred_df['price'], color='blue');\n",
    "    plt.scatter(pred_df['recnum'],\n",
    "                pred_df['predicted'], \n",
    "                pred_df['error_pct'], \n",
    "                color='red');\n",
    "\n",
    "    ax.legend(['Actual','Predicted'], \n",
    "              loc='lower center',\n",
    "              ncol=2, \n",
    "              title=chart_description)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Compare the predicted prices to actual prices\n",
    "compare_pred_to_actual('House prices predicted using linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_list = ['price','bedrooms']\n",
    "\n",
    "for feature in feature_list:\n",
    "    plt.figure(figsize=(20,2))\n",
    "    bplot = sb.boxplot(x=feature, data=data_raw, orient=\"h\", fliersize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine data values in the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Houses with a value above $6,000,000\n",
    "data_train.loc[data_train_labels['price'] > 6000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houses with more than 11 bedrooms\n",
    "data_train.loc[data_train['bedrooms'] > 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop outliers from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{len(data_train):6d} houses in the training dataset')\n",
    "\n",
    "# Keep only the rows for houses priced $6M or less\n",
    "data_train = data_train.loc[data_train_labels['price'] <= 6000000]\n",
    "data_train_labels = data_train_labels.loc[data_train_labels['price'] <= 6000000]\n",
    "print(f'{len(data_train):6d} houses remain after dropping those priced over $6M')\n",
    "\n",
    "# Keep only the rows for houses with 11 or fewer bedrooms\n",
    "data_train_labels = data_train_labels.loc[data_train['bedrooms'] <= 11]\n",
    "data_train = data_train.loc[data_train['bedrooms'] <= 11]\n",
    "print(f'{len(data_train):6d} houses remain after dropping those with more than 11 bedrooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show statistics for the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show statistics for the features we'll be using, to prepare for feature scaling.\n",
    "with pd.option_context('float_format', '{:.2f}'.format):\n",
    "    print(data_train['sqft_living'].describe(), '\\n')\n",
    "    print(data_train_labels['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the scale and distribution of price and sqft_living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare scale and distribution of price and sqft_living\n",
    "def compare_price_sqft():\n",
    "\n",
    "    print('Maximum price =', data_train_labels.loc[data_train_labels['price'].idxmax()]['price']);\n",
    "    print('Maximum sqft_living =', data_train.loc[data_train['sqft_living'].idxmax()]['sqft_living']);\n",
    "\n",
    "    fig = plt.figure(figsize=(15,3))\n",
    "    fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "    plt.rc('axes', titlesize=9)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=11)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=8)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=8)    # fontsize of the tick labels\n",
    "\n",
    "    ax1=fig.add_subplot(1, 3, 1)\n",
    "    plt.xlabel('price')\n",
    "    plt.hist(data_train_labels['price'], label='price');\n",
    "\n",
    "    ax2=fig.add_subplot(1, 3, 2)\n",
    "    plt.xlabel('sqft_living')\n",
    "    plt.hist(data_train['sqft_living'], label='sqft_living');\n",
    "\n",
    "    # View relationship between price and sqft_living\n",
    "    ax2=fig.add_subplot(1, 3, 3)\n",
    "    sb.scatterplot(x=data_train_labels['price'], y=data_train['sqft_living']);\n",
    "    \n",
    "compare_price_sqft()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform price and sqft_living, and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a log transformation to scale price and sqft_living\n",
    "data_train['sqft_living'] = np.log(data_train['sqft_living'])\n",
    "data_train_labels['price'] = np.log(data_train_labels['price'])\n",
    "\n",
    "# Log transformation must be applied to test dataset as well\n",
    "data_test['sqft_living'] = np.log(data_test['sqft_living'])\n",
    "data_test_labels['price'] = np.log(data_test_labels['price'])\n",
    "\n",
    "# Compare scale and distribution of price and sqft_living\n",
    "compare_price_sqft()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and test a linear regression model - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a linear regression model and fit it using the training data\n",
    "regressor = LinearRegression()\n",
    "\n",
    "start = time()\n",
    "regressor.fit(data_train, data_train_labels);\n",
    "end=time()\n",
    "train_time = (end - start) * 1000\n",
    "print('Model took {:,.2f} milliseconds to fit.'.format(train_time))\n",
    "\n",
    "# Evaluate the model's performance\n",
    "score = regressor.score(data_test, data_test_labels)\n",
    "'Score: {}%'.format(int(round(score * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the first ten predictions to actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# y_pred is the predicted prices that will be produced by testing\n",
    "predicted_prices = regressor.predict(data_test)\n",
    "predictions = data_test_labels.copy()\n",
    "predictions['predicted'] = predicted_prices\n",
    "\n",
    "# View examples of the transformed prices\n",
    "with pd.option_context('float_format', '${:,.2f}'.format): print( predictions.head(10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the prices back to actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to call exp() function to convert back from log value to actual price.\n",
    "import math\n",
    "predictions = predictions.applymap(math.exp)\n",
    "\n",
    "# View examples of the actual and predicted prices\n",
    "with pd.option_context('float_format', '${:,.2f}'.format): print( predictions.head(10) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare predicted values to actual values (Round 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the predicted prices to actual prices\n",
    "compare_pred_to_actual('House prices predicted using linear regression (Round 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try a different algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a model using the random forest algorithm.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rnd_forest = RandomForestRegressor(n_estimators=100,random_state=0)\n",
    "\n",
    "start = time()\n",
    "rnd_forest.fit(data_train, data_train_labels.values.ravel())\n",
    "end=time()\n",
    "train_time = (end - start) * 1000\n",
    "print('Model took {:,.2f} milliseconds to fit.'.format(train_time))\n",
    "\n",
    "score = rnd_forest.score(data_test, data_test_labels)\n",
    "print('Score: {}%'.format(int(round(score * 100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View examples of the actual and predicted prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = rnd_forest.predict(data_test)\n",
    "\n",
    "predictions = data_test_labels.copy()\n",
    "predictions['predicted'] = predicted_prices\n",
    "\n",
    "# Scale the prices back to actual values.\n",
    "predictions = predictions.applymap(math.exp)\n",
    "\n",
    "# View examples of the actual and predicted prices\n",
    "with pd.option_context('float_format', '${:,.2f}'.format): print( predictions.head(10) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the new predicted prices to actual prices\n",
    "compare_pred_to_actual('House prices predicted using random forest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
