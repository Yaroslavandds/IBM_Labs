{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries and load the dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys                                             # Read system parameters.\n",
    "import numpy as np                                     # Work with multi-dimensional arrays and matrices.\n",
    "import pandas as pd                                    # Manipulate and analyze data.\n",
    "import sklearn                                         # Perform data mining and analysis.\n",
    "from sklearn import datasets\n",
    "from time import time                                  # Calculate training time.\n",
    "\n",
    "# Summarize software libraries used.\n",
    "print('Libraries used in this project:')\n",
    "print('- Python {}'.format(sys.version))\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- pandas {}'.format(pd.__version__))\n",
    "print('- scikit-learn {}\\n'.format(sklearn.__version__))\n",
    "\n",
    "# Load the dataset.\n",
    "boston = datasets.load_boston()\n",
    "print('Loaded {} records.'.format(len(boston.data)))\n",
    "\n",
    "# Convert array to pandas DataFrame.\n",
    "data_raw = pd.DataFrame(boston['data'], columns = boston['feature_names'])\n",
    "data_raw['target'] = boston['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 'target' is the dependent variable (value to be predicted), so it will be\n",
    "# removed from the training data and put into a separate DataFrame for labels.\n",
    "label_columns = ['target']\n",
    "\n",
    "# Split the training and test datasets and their labels.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_raw.loc[:, 'CRIM': 'LSTAT'],\n",
    "                                                                            data_raw[label_columns],\n",
    "                                                                            random_state = 2)\n",
    "\n",
    "# Compare the number of rows and columns in the original data to the training and test sets.\n",
    "print(f'Original set:        {data_raw.shape}')\n",
    "print('------------------------------')\n",
    "print(f'Training features:   {X_train.shape}')\n",
    "print(f'Test features:       {X_test.shape}')\n",
    "print(f'Training labels:     {y_train.shape}')\n",
    "print(f'Test labels:         {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns that won't be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column from dataset that shows weak correlation.\n",
    "def drop_unused(dataset):\n",
    "    \n",
    "    print('Columns before drop:\\n\\n{}\\n'.format(list(dataset.columns)))\n",
    "        \n",
    "    dataset = dataset.drop(['CHAS'], axis = 1)\n",
    "    \n",
    "    print('Columns after drop:\\n\\n{}\\n'.format(list(dataset.columns)))\n",
    "    return dataset\n",
    "\n",
    "X_train, X_test = drop_unused(X_train.copy()), drop_unused(X_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    result = X.copy()\n",
    "    \n",
    "    for feature in X.columns:\n",
    "        result[feature] = (X[feature] - X[feature].mean()) / X[feature].std()  # z-score formula.\n",
    "        \n",
    "    return result\n",
    "\n",
    "X_train = standardize(X_train)\n",
    "X_test = standardize(X_test)\n",
    "\n",
    "print('The features have been standardized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model and calculate its cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def model_train(model):\n",
    "    start = time()\n",
    "    model.fit(X_train, np.ravel(y_train))\n",
    "    end = time()\n",
    "    train_time = (end - start) * 1000\n",
    "    \n",
    "    predict = model.predict(X_test)\n",
    "    \n",
    "    cost = mse(y_test, predict)\n",
    "    \n",
    "    print('Linear regression model took {:.2f} milliseconds to fit.'.format(train_time))\n",
    "    print('Cost (mean squared error): {:.2f}'.format(cost))\n",
    "    \n",
    "print('The function to train the model and calculate its cost has been defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate linear regression models using both closed-form and iterative solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Create closed-form and iterative ridge regression models.\n",
    "def model_eval(eta):\n",
    "    for name, model in [\n",
    "        ('Ridge regression (closed form)', Ridge(alpha = 0.1, solver = 'cholesky')),\n",
    "        ('Ridge regression (gradient descent)', SGDRegressor(penalty = 'l2',\n",
    "                                                             alpha = 0.1,\n",
    "                                                             tol = 1e-3,\n",
    "                                                             learning_rate = 'constant',\n",
    "                                                             eta0 = eta,\n",
    "                                                             random_state = 2))]:\n",
    "\n",
    "        print('Model: {}'.format(name))\n",
    "        print('--------------------')\n",
    "        model_train(model)\n",
    "        print('\\n')\n",
    "        \n",
    "print('The function to evaluate the linear regression models has been defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
