{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import software libraries and load the dataset #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries used in this project:\n",
      "- Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) \n",
      "[GCC 7.3.0]\n",
      "- NumPy 1.16.2\n",
      "- Matplotlib 3.0.3\n",
      "- scikit-learn 0.20.3\n",
      "- TensorFlow 2.0.0\n",
      "- Keras 2.3.1\n",
      "\n",
      "Loaded 60000 training records.\n",
      "Loaded 10000 test records.\n"
     ]
    }
   ],
   "source": [
    "import sys                             # Read system parameters.\n",
    "import shutil\n",
    "import numpy as np                     # Work with multi-dimensional arrays and matrices.\n",
    "from numpy.random import seed\n",
    "import matplotlib as mpl               # Create 2D charts.\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn                         # Perform data mining and analysis.\n",
    "import tensorflow                      # Train neural networks for deep learning.\n",
    "import keras                           # Provide a frontend for TensorFlow.\n",
    "from keras import datasets\n",
    "\n",
    "# Summarize software libraries used.\n",
    "print('Libraries used in this project:')\n",
    "print('- Python {}'.format(sys.version))\n",
    "print('- NumPy {}'.format(np.__version__))\n",
    "print('- Matplotlib {}'.format(mpl.__version__))\n",
    "print('- scikit-learn {}'.format(sklearn.__version__))\n",
    "print('- TensorFlow {}'.format(tensorflow.__version__))\n",
    "print('- Keras {}\\n'.format(keras.__version__))\n",
    "\n",
    "# Load the dataset.\n",
    "shutil.rmtree('/home/jovyan/.keras')\n",
    "shutil.copytree('/home/jovyan/work/.keras', '/home/jovyan/.keras')\n",
    "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "print('Loaded {} training records.'.format(len(X_train.data)))\n",
    "print('Loaded {} test records.'.format(len(X_test.data)))\n",
    "\n",
    "# Uncomment the following two lines to make outcomes deterministic. Supply whatever seed values you wish.\n",
    "#seed(1)\n",
    "#tensorflow.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get acquainted with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of feature space: {}\\n'.format(X_train[0].shape))\n",
    "\n",
    "print('A few examples:\\n')\n",
    "print(X_train[7:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "for i in range(10):\n",
    "    print('{} ({})'.format(class_names[i], np.unique(y_train)[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot just first example for now.\n",
    "plt.imshow(X_train[0], cmap = 'gray')\n",
    "plt.title('Class: {} ({})'.format(class_names[y_train[0]], y_train[0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 5, figsize = (8, 8))\n",
    "\n",
    "for i, ax in zip(range(25), axes.flatten()):\n",
    "    ax.imshow(X_train[i,:,:], cmap = 'gray')  # Plot training example.\n",
    "    ax.title.set_text('Class: {}\\n({})'.format(class_names[y_train[i]], y_train[i]))\n",
    "\n",
    "# Turn off axis ticks for readability.\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for training with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays to add greyscale flag.\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode the data for each label.\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print('One-hot encoding for first image: {}'.format(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training and validation datasets and their labels.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 50)\n",
    "\n",
    "print(f'Training features:         {X_train.shape}')\n",
    "print(f'Validation features:       {X_val.shape}')\n",
    "print(f'Training labels:           {y_train.shape}')\n",
    "print(f'Validation labels:         {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "# Start stacking layers one-by-one.\n",
    "cnn.add(Conv2D(filters = 32,\n",
    "               kernel_size = (3, 3),  # First convolutional layer (32 output filters, 3x3 filter size).\n",
    "               input_shape = (28, 28, 1),\n",
    "               padding = 'same',\n",
    "               activation = 'linear'))  # Will add leaky ReLU layer next.\n",
    "cnn.add(LeakyReLU(alpha = 0.1))\n",
    "cnn.add(MaxPooling2D((2, 2), padding = 'same'))  # First pooling layer with 2x2 size.\n",
    "\n",
    "cnn.add(Conv2D(64, (3, 3), padding = 'same', activation = 'linear'))\n",
    "cnn.add(LeakyReLU(alpha = 0.1))\n",
    "cnn.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "cnn.add(Conv2D(128, (3, 3), padding = 'same', activation = 'linear'))\n",
    "cnn.add(LeakyReLU(alpha = 0.1))                  \n",
    "cnn.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "\n",
    "cnn.add(Flatten())  # Connect convolution and dense layer.\n",
    "cnn.add(Dense(10, activation = 'softmax'))  # Dense output layer with softmax activation.\n",
    "\n",
    "print('The CNN structure has been built.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model and examine the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam',\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required library.\n",
    "!conda install --yes graphviz==2.40.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(cnn, show_shapes = True, to_file = 'model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_trained = cnn.fit(X_train, y_train,\n",
    "                      validation_data = (X_val, y_val),\n",
    "                      epochs = 1,\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_test = cnn.evaluate(X_test, y_test, verbose = 0)\n",
    "\n",
    "print('Loss: {}'.format(round(eval_test[0], 2)))\n",
    "print('Accuracy: {:.0f}%'.format(eval_test[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cnn.predict(X_test)\n",
    "prediction = np.argmax(np.round(prediction), axis = 1)  # Extract class number from one-hot-encoded array.\n",
    "actual = np.argmax(np.round(y_test), axis = 1)\n",
    "\n",
    "print('Actual class:    {}'.format(actual[:10]))\n",
    "print('Predicted class: {}'.format(prediction[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the predictions for several examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 5, figsize = (12, 12))\n",
    "\n",
    "for i, ax in zip(range(25), axes.flatten()):\n",
    "    \n",
    "    if actual[i] == prediction[i]:\n",
    "        ax.imshow(X_test[i].reshape(28, 28), cmap = 'gray')\n",
    "    else:\n",
    "        ax.imshow(X_test[i].reshape(28, 28))  # Highlight wrong predictions.\n",
    "        \n",
    "    ax.title.set_text('Actual: {} ({})\\nPredicted: {} ({})'.format(class_names[actual[i]], actual[i],\n",
    "                                                                   class_names[prediction[i]], prediction[i]))\n",
    "\n",
    "# Turn off axis ticks for readability.\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
